{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-25T18:56:17.614665600Z",
     "start_time": "2024-04-25T18:56:11.680186300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/IND/AXISBANK.NS.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T14:17:56.978994600Z",
     "start_time": "2024-03-28T14:17:56.932833500Z"
    }
   },
   "id": "a41052dcfca1915a",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data.drop(['Open', 'High', 'Low', 'Close', 'Volume'], axis = 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T14:19:30.355247100Z",
     "start_time": "2024-03-28T14:19:30.338685300Z"
    }
   },
   "id": "e44de13f2b3a5ffd",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data[\"x_close\"] = np.log(data[\"Adj Close\"]/data[\"Adj Close\"].shift(1))\n",
    "data[\"y_close\"] = np.log(data[\"Adj Close\"]/data[\"Adj Close\"].shift(2)) + 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T03:54:13.637685200Z",
     "start_time": "2024-03-29T03:54:13.609253700Z"
    }
   },
   "id": "45cc92d04190bb04",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date   Adj Close   x_close   y_close\n",
      "2     2003-01-06    6.809484 -0.001190  0.977633\n",
      "3     2003-01-07    6.817590  0.001190  1.000000\n",
      "4     2003-01-08    6.955401  0.020012  1.021202\n",
      "5     2003-01-09    7.012148  0.008126  1.028138\n",
      "6     2003-01-10    7.190493  0.025116  1.033241\n",
      "7     2003-01-13    7.190493  0.000000  1.025116\n",
      "8     2003-01-14    7.166172 -0.003388  0.996612\n",
      "9     2003-01-15    7.303981  0.019048  1.015660\n",
      "10    2003-01-16    7.490432  0.025207  1.044255\n",
      "11    2003-01-17    7.231023 -0.035246  0.989961\n",
      "12    2003-01-20    7.263451  0.004475  0.969229\n",
      "13    2003-01-21    7.466115  0.027520  1.031994\n",
      "14    2003-01-22    7.385048 -0.010917  1.016602\n",
      "15    2003-01-23    7.571498  0.024934  1.014016\n",
      "16    2003-01-24    7.222918 -0.047132  0.977802\n",
      "17    2003-01-27    6.874336 -0.049464  0.903404\n",
      "18    2003-01-28    6.963508  0.012888  0.963424\n",
      "19    2003-01-29    6.866230 -0.014068  0.998820\n",
      "20    2003-01-30    6.760845 -0.015467  0.970464\n",
      "21    2003-01-31    6.785164  0.003591  0.988123\n",
      "22    2003-02-03    6.817590  0.004768  1.008358\n",
      "23    2003-02-04    6.833804  0.002375  1.007143\n",
      "24    2003-02-05    6.785164 -0.007143  0.995232\n",
      "25    2003-02-06    6.914869  0.018935  1.011793\n",
      "26    2003-02-07    6.882442 -0.004700  1.014235\n",
      "27    2003-02-10    6.793272 -0.013041  0.982259\n",
      "28    2003-02-11    6.655460 -0.020495  0.966464\n",
      "29    2003-02-12    6.606821 -0.007335  0.972170\n",
      "30    2003-02-13    6.606821  0.000000  0.992665\n",
      "31    2003-02-14    6.387945 -0.033690  0.966310\n",
      "...          ...         ...       ...       ...\n",
      "4143  2019-09-16  669.197510 -0.004981  1.011996\n",
      "4144  2019-09-17  638.824707 -0.046449  0.948570\n",
      "4145  2019-09-18  646.754578  0.012337  0.965888\n",
      "4146  2019-09-19  636.580444 -0.015856  0.996481\n",
      "4147  2019-09-20  678.623413  0.063956  1.048099\n",
      "4148  2019-09-23  723.658875  0.064254  1.128209\n",
      "4149  2019-09-24  702.612427 -0.029515  1.034739\n",
      "4150  2019-09-25  693.186401 -0.013506  0.956979\n",
      "4151  2019-09-26  698.123901  0.007098  0.993591\n",
      "4152  2019-09-27  698.822021  0.000999  1.008097\n",
      "4153  2019-09-30  683.261658 -0.022518  0.978481\n",
      "4154  2019-10-01  677.426514 -0.008577  0.968905\n",
      "4155  2019-10-03  666.703796 -0.015955  0.975468\n",
      "4156  2019-10-04  654.734253 -0.018116  0.965928\n",
      "4157  2019-10-07  671.740967  0.025643  1.007527\n",
      "4158  2019-10-09  684.558350  0.018901  1.044544\n",
      "4159  2019-10-10  671.242249 -0.019644  0.999257\n",
      "4160  2019-10-11  670.992920 -0.000372  0.979985\n",
      "4161  2019-10-14  681.765442  0.015927  1.015556\n",
      "4162  2019-10-15  688.298828  0.009537  1.025465\n",
      "4163  2019-10-16  691.640320  0.004843  1.014380\n",
      "4164  2019-10-17  708.497437  0.024080  1.028923\n",
      "4165  2019-10-18  707.749329 -0.001056  1.023024\n",
      "4166  2019-10-22  710.941284  0.004500  1.003443\n",
      "4167  2019-10-23  713.035889  0.002942  1.007442\n",
      "4168  2019-10-24  705.904053 -0.010052  0.992889\n",
      "4169  2019-10-25  706.801758  0.001271  0.991218\n",
      "4170  2019-10-27  708.297974  0.002115  1.003386\n",
      "4171  2019-10-29  736.576050  0.039148  1.041262\n",
      "4172  2019-10-30  745.503357  0.012047  1.051195\n",
      "\n",
      "[4171 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df_sliced = data[2:]  # Exclude the first 2 rows"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T03:55:54.879277100Z",
     "start_time": "2024-03-29T03:55:54.848725600Z"
    }
   },
   "id": "69cbbedf34fac7a3",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Desktop\\MTP Peoject\\waveCorr-main\\venv\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "df_sliced.drop([\"Adj Close\"], axis = 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T03:56:23.732600Z",
     "start_time": "2024-03-29T03:56:23.434165900Z"
    }
   },
   "id": "fd6e25ed7f6daba3",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "path = 'data/aaa'\n",
    "\n",
    "def list_all_files_and_folders(directory, files = []):\n",
    "    for entry in os.listdir(directory):\n",
    "        full_path = os.path.join(directory, entry)\n",
    "        if os.path.isdir(full_path):\n",
    "            list_all_files_and_folders(full_path, files)  # Recursive call for subdirectories\n",
    "        else:\n",
    "            files.append(full_path[8:])\n",
    "    return files\n",
    "\n",
    "files = list_all_files_and_folders(path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T18:56:34.813114800Z",
     "start_time": "2024-04-25T18:56:34.434801400Z"
    }
   },
   "id": "b51d8561b4b1ec51",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Desktop\\MTP Peoject\\waveCorr-main\\venv\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in log\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    data = pd.read_csv(\"data/aaa\" + file)\n",
    "    data.drop(['Open', 'High', 'Low', 'Close', 'Volume'], axis = 1, inplace = True)\n",
    "    \n",
    "    data[\"x_close\"] = np.log(data[\"Adj Close\"]/data[\"Adj Close\"].shift(1))\n",
    "    data[\"y_close\"] = data[\"x_close\"].shift(-2) + 1\n",
    "    \n",
    "    df_sliced = data[2:]  # Exclude the first 2 rows\n",
    "    df_sliced.drop([\"Adj Close\"], axis = 1, inplace = True)\n",
    "    \n",
    "    df_sliced.rename(columns = {\"Date\": \"date\"}, inplace = True)\n",
    "    # print(len(df_sliced))\n",
    "    \n",
    "    df_sliced.to_csv(\"data/aab\" + file, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T19:10:20.298255Z",
     "start_time": "2024-04-25T18:57:12.961377700Z"
    }
   },
   "id": "21e930c04217af12",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Define a list to store results\n",
    "all_data = []\n",
    "\n",
    "# Loop through all CSV files using glob\n",
    "for filename in glob.glob(\"*.csv\"):\n",
    "  # Read the CSV file\n",
    "  data = pd.read_csv(filename)\n",
    "  \n",
    "  # Get descriptive statistics for X_close and Y_close columns\n",
    "  stats = data[['X_close', 'Y_close']].describe(percentiles=[0.25, 0.75])\n",
    "  \n",
    "  # Add filename as 'name' column and handle missing values (if any)\n",
    "  stats['name'] = filename\n",
    "  stats.fillna(method='ffill', inplace=True)  # Forward fill missing values\n",
    "  \n",
    "  # Add statistics to the all_data list\n",
    "  all_data.append(stats)\n",
    "\n",
    "# Combine all data into a single DataFrame\n",
    "df_all_stats = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Print the DataFrame containing means, quartiles, and std_dev\n",
    "print(df_all_stats)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fefd74a5d33485e9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "path = 'data/ind'\n",
    "\n",
    "def list_all_files_and_folders(directory, files = []):\n",
    "    for entry in os.listdir(directory):\n",
    "        full_path = os.path.join(directory, entry)\n",
    "        if os.path.isdir(full_path):\n",
    "            list_all_files_and_folders(full_path, files)  # Recursive call for subdirectories\n",
    "        else:\n",
    "            files.append(full_path[8:])\n",
    "    return files\n",
    "\n",
    "files = list_all_files_and_folders(path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T06:15:35.937418500Z",
     "start_time": "2024-04-25T06:15:35.911750700Z"
    }
   },
   "id": "afe6a2534bbd8361",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/ind\" + files[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T06:16:49.672666200Z",
     "start_time": "2024-04-25T06:16:49.637016600Z"
    }
   },
   "id": "117e2ced69875c5b",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           x_close      y_close\ncount  4174.000000  4174.000000\nmean      0.001595     1.003193\nstd       0.027949     0.041507\nmin      -0.154661     0.726256\n25%      -0.012985     0.981904\n50%       0.000000     1.000676\n75%       0.013193     1.021297\nmax       0.531169     1.558607",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x_close</th>\n      <th>y_close</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4174.000000</td>\n      <td>4174.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.001595</td>\n      <td>1.003193</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.027949</td>\n      <td>0.041507</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-0.154661</td>\n      <td>0.726256</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-0.012985</td>\n      <td>0.981904</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>1.000676</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.013193</td>\n      <td>1.021297</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.531169</td>\n      <td>1.558607</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = data[['x_close', 'y_close']].describe(percentiles=[0.25, 0.75])\n",
    "stats"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T06:22:06.485840600Z",
     "start_time": "2024-04-25T06:22:06.449284600Z"
    }
   },
   "id": "447cb4f79391a072",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       x_close      y_close              name\n",
      "0  4174.000000  4174.000000  \\AARTIIND.NS.csv\n",
      "1     0.001595     1.003193  \\AARTIIND.NS.csv\n",
      "2     0.027949     0.041507  \\AARTIIND.NS.csv\n",
      "3    -0.154661     0.726256  \\AARTIIND.NS.csv\n",
      "4    -0.012985     0.981904  \\AARTIIND.NS.csv\n",
      "5     0.000000     1.000676  \\AARTIIND.NS.csv\n",
      "6     0.013193     1.021297  \\AARTIIND.NS.csv\n",
      "7     0.531169     1.558607  \\AARTIIND.NS.csv\n"
     ]
    }
   ],
   "source": [
    "stats['name'] = files[0]\n",
    "stats.fillna(method='ffill', inplace=True)  # Forward fill missing values\n",
    "all_data = []\n",
    "all_data.append(stats)\n",
    "df_all_stats = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Print the DataFrame containing means, quartiles, and std_dev\n",
    "print(df_all_stats)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T06:18:18.588836500Z",
     "start_time": "2024-04-25T06:18:18.556908500Z"
    }
   },
   "id": "770e43503deebf67",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "path = 'data/ind'\n",
    "\n",
    "def list_all_files_and_folders(directory, files = []):\n",
    "    for entry in os.listdir(directory):\n",
    "        full_path = os.path.join(directory, entry)\n",
    "        if os.path.isdir(full_path):\n",
    "            list_all_files_and_folders(full_path, files)  # Recursive call for subdirectories\n",
    "        else:\n",
    "            files.append(full_path[8:])\n",
    "    return files\n",
    "\n",
    "files = list_all_files_and_folders(path)\n",
    "# Define a dictionary to store results\n",
    "all_data = {}\n",
    "\n",
    "# Loop through all CSV files using glob\n",
    "for filename in files:\n",
    "  # Read the CSV file\n",
    "  data = pd.read_csv(\"data/ind\" + filename)\n",
    "  \n",
    "  # Get descriptive statistics for X_close and Y_close columns\n",
    "  stats = data[['x_close', 'y_close']].describe(percentiles=[0.25, 0.75])\n",
    "  \n",
    "  # Extract and format desired statistics\n",
    "  summary = {\n",
    "      'name': filename,\n",
    "      'mean_x_close': stats['x_close']['mean'],\n",
    "      'mean_y_close': stats['y_close']['mean'],\n",
    "      'std_x_close': stats['x_close']['std'],\n",
    "      'std_y_close': stats['y_close']['std'],\n",
    "      # 'q1_x_close': stats['x_close'][0.25],\n",
    "      # 'q1_y_close': stats['y_close'][0.25],\n",
    "      # 'q3_x_close': stats['x_close'][0.75],\n",
    "      # 'q3_y_close': stats['y_close'][0.75],\n",
    "  }\n",
    "  \n",
    "  # Add statistics to the all_data dictionary with filename as key\n",
    "  all_data[filename] = summary\n",
    "\n",
    "# Convert dictionary to a DataFrame\n",
    "df_all_stats = pd.DataFrame(all_data.values())\n",
    "\n",
    "# Print the DataFrame with desired statistics\n",
    "df_all_stats.to_excel(\"ind_stats.xlsx\", index = False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T06:31:41.683505600Z",
     "start_time": "2024-04-25T06:31:39.923682900Z"
    }
   },
   "id": "ae92492c8dcc664f",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = 'data/can'\n",
    "\n",
    "def list_all_files_and_folders(directory, files = []):\n",
    "    for entry in os.listdir(directory):\n",
    "        full_path = os.path.join(directory, entry)\n",
    "        if os.path.isdir(full_path):\n",
    "            list_all_files_and_folders(full_path, files)  # Recursive call for subdirectories\n",
    "        else:\n",
    "            files.append(full_path[8:])\n",
    "    return files\n",
    "\n",
    "files = list_all_files_and_folders(path)\n",
    "\n",
    "# Define a dictionary to store results\n",
    "all_data = {}\n",
    "\n",
    "# Loop through all CSV files using glob\n",
    "for filename in files:\n",
    "  # Read the CSV file\n",
    "  data = pd.read_csv(\"data/can\" + filename)\n",
    "  \n",
    "  # Get descriptive statistics for X_close and Y_close columns\n",
    "  stats = data[['x_close', 'y_close']].describe(percentiles=[0.25, 0.75])\n",
    "  \n",
    "  # Extract and format desired statistics\n",
    "  summary = {\n",
    "      'name': filename,\n",
    "      'mean_x_close': stats['x_close']['mean'],\n",
    "      'mean_y_close': stats['y_close']['mean'],\n",
    "      'std_x_close': stats['x_close']['std'],\n",
    "      'std_y_close': stats['y_close']['std'],\n",
    "      # 'q1_x_close': stats['x_close'][0.25],\n",
    "      # 'q1_y_close': stats['y_close'][0.25],\n",
    "      # 'q3_x_close': stats['x_close'][0.75],\n",
    "      # 'q3_y_close': stats['y_close'][0.75],\n",
    "  }\n",
    "  \n",
    "  # Add statistics to the all_data dictionary with filename as key\n",
    "  all_data[filename] = summary\n",
    "\n",
    "# Convert dictionary to a DataFrame\n",
    "df_all_stats = pd.DataFrame(all_data.values())\n",
    "\n",
    "# Print the DataFrame with desired statistics\n",
    "df_all_stats.to_excel(\"can_stats.xlsx\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T06:33:15.461045300Z",
     "start_time": "2024-04-25T06:33:13.910771900Z"
    }
   },
   "id": "6e19e18e12614b23",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(np.empty([20,0,2]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T13:09:56.713706600Z",
     "start_time": "2024-04-25T13:09:56.688268200Z"
    }
   },
   "id": "73aa96bf8924e554",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T13:08:09.345228200Z",
     "start_time": "2024-04-25T13:08:09.320235600Z"
    }
   },
   "id": "86de7127ac53cda7",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a62dbadabaf0ee9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
